{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "../../../python_for_probability_statistics_and_machine_learning.jpg",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image \n",
    "Image('../../../python_for_probability_statistics_and_machine_learning.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- add feature importances from RandomForestClassifier -->\n",
    "<!-- ensemble methods - references below -->\n",
    "<!-- D:\\Volume2_Indexed\\Encyclopedia_of_machine_learning_Sammut.pdf -->\n",
    "<!-- D:\\Volume2_Indexed\\Data_Mining_With_Decision_Trees_Rokach.pdf -->\n",
    "<!-- D:\\Volume2_Indexed\\Data_Mining_Kantardzic.pdf -->\n",
    "<!-- D:\\Volume2_Indexed\\Machine_Learning_with_R_Cookbook_Yu-Wei.pdf -->\n",
    "<!-- D:\\Volume2_Indexed\\Data_Mining_Witten.pdf -->\n",
    "<!-- D:\\Volume2_Indexed\\Elements_of_Statistical_Learning_Hastie.pdf -->\n",
    "<!-- D:\\Volume2_Indexed\\Independent_Component_Analysis_Hyvarinen.pdf -->\n",
    "<!-- D:\\Volume2_Indexed\\Data_Mining_and_Statisticas_Tuffery.pdf -->\n",
    "<!-- D:\\Volume2_Indexed\\Machine_Learning_Probabilistic_Perspective_Murphy.pdf\n",
    "-->\n",
    "<!-- D:\\Volume2_Indexed\\Machine_Learning_Flach.pdf -->\n",
    "\n",
    "A decision tree is the easiest classifer to understand, interpret, and explain.\n",
    "A decision tree is constructed by recursively splitting the data set into a\n",
    "sequence of subsets based on if-then questions.  The training set consists of\n",
    "pairs $(\\mathbf{x},y)$ where $\\mathbf{x}\\in \\mathbb{R}^d$ where $d$ is the\n",
    "number of features available and where $y$ is the corresponding label. The\n",
    "learning method splits the training set into groups based on $\\mathbf{x}$ while\n",
    "attempting to keep the assignments in each group as uniform as possible. In\n",
    "order to\n",
    "do this, the learning method must pick a feature and an associated threshold for\n",
    "that feature upon which to\n",
    "divide the data.  This is tricky to explain in words, but easy to see with\n",
    "an example. First, let's set up the Scikit-learn classifer,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pylab import subplots\n",
    "from numpy import ma\n",
    "import numpy as np\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also create some example data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1]\n",
      " [0 0 1 1]\n",
      " [0 0 1 1]\n",
      " [0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "M=np.fromfunction(lambda i,j:j>=2,(4,4)).astype(int)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Programming Tip.**\n",
    "\n",
    "The `fromfunction` creates Numpy arrays using the indicies as inputs\n",
    "to a function whose value is the corresponding array entry.\n",
    "\n",
    "\n",
    "\n",
    "We want to classify the elements of the matrix based on their\n",
    "respective positions in the matrix. By just looking at the matrix, the\n",
    "classification is pretty simple --- classify as `0` for any positions in the\n",
    "first two columns of the matrix, and classify `1` otherwise.  Let's walk\n",
    "through this formally and see if this solution emerges from the decision\n",
    "tree.  The values of the array are the labels for the training set and the\n",
    "indicies of those values are the elements of $\\mathbf{x}$. Specifically, the\n",
    "training set has $\\mathcal{X} = \\left\\{(i,j)\\right\\}$ and\n",
    "$\\mathcal{Y}=\\left\\{0,1\\right\\}$ Now, let's extract those elements and construct\n",
    "the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [2 0]\n",
      " [2 1]\n",
      " [3 0]\n",
      " [3 1]]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "i,j = np.where(M==0) \n",
    "x=np.vstack([i,j]).T # build nsamp by nfeatures\n",
    "y = j.reshape(-1,1)*0 # 0 elements\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the elements of `x` are the two-dimensional indicies of the\n",
    "values of `y`. For example, `M[x[0,0],x[0,1]]=y[0,0]`. Likewise,\n",
    "to complete the training set, we just need to stack the rest of the data to\n",
    "cover\n",
    "all the cases,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i,j = np.where(M==1)  \n",
    "x=np.vstack([np.vstack([i,j]).T,x ]) # build nsamp x nfeatures\n",
    "y=np.vstack([j.reshape(-1,1)*0+1,y]) # 1 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all that established, all we have to do is train the classifer,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate how the classifer performed, we can report the score,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this classifer, the *score* is the accuracy, which is\n",
    "defined as the ratio of the sum of the true-positive ($TP$) and\n",
    "true-negatives ($TN$) divided by the sum of all the terms, including\n",
    "the false terms,\n",
    "\n",
    "$$\n",
    "\\texttt{accuracy}=\\frac{TP+TN}{TP+TN+FN+FP}\n",
    "$$\n",
    "\n",
    "In this case, the classifier gets every point correctly, so\n",
    "$FN=FP=0$. On a related note, two other common names from information retrieval\n",
    "theory are  *recall* (a.k.a. sensitivity) and *precision* (a.k.a. positive\n",
    "predictive value, $TP/(TP+FP)$).  We can visualize this tree in\n",
    "[Figure](#fig:example_tree_001). The Gini coefficients (a.k.a. categorical\n",
    "variance)\n",
    "in the figure are a measure of the purity of each so-determined class. This\n",
    "coefficient is defined as,\n",
    "\n",
    "<!-- dom:FIGURE: [fig-machine_learning/example_tree_001.png, width=500 frac=0.5]\n",
    "Example decision tree. The `Gini` coefficient in each branch measures the purity\n",
    "of the partition in each node.  The `samples` item in the box shows the number\n",
    "of items in the corresponding node in the decision tree. <div\n",
    "id=\"fig:example_tree_001\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:example_tree_001\"></div>\n",
    "\n",
    "<p>Example decision tree. The <code>Gini</code> coefficient in each branch\n",
    "measures the purity of the partition in each node.  The <code>samples</code>\n",
    "item in the box shows the number of items in the corresponding node in the\n",
    "decision tree.</p>\n",
    "<img src=\"fig-machine_learning/example_tree_001.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "$$\n",
    "\\texttt{Gini}_m = \\sum_k p_{m,k}(1-p_{m,k})\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "p_{m,k} = \\frac{1}{N_m} \\sum_{x_i\\in R_m} I(y_i=k)\n",
    "$$\n",
    "\n",
    "which is the proportion of observations labeled $k$ in the $m^{th}$\n",
    "node and $I(\\cdot)$ is the usual indicator function. Note that the maximum value\n",
    "of\n",
    "the Gini coefficient is $\\max{\\texttt{Gini}_{m}}=1-1/m$. For our simple\n",
    "example, half of the sixteen samples are in category `0` and the other half are\n",
    "in the `1` category.  Using the notation above, the top box corresponds to the\n",
    "$0^{th}$ node, so $p_{0,0} =1/2 = p_{0,1}$. Then, $\\texttt{Gini}_0=0.5$. The\n",
    "next layer of nodes in [Figure](#fig:example_tree_001) is determined by\n",
    "whether or not the second dimension of the $\\mathbf{x}$ data is greater than\n",
    "`1.5`. The Gini coefficients for each of these child nodes is zero because\n",
    "after the prior split, each subsequent category is pure. The `value` list in\n",
    "each of the nodes shows the distribution of elements in each category at each\n",
    "node.\n",
    "\n",
    "To make this example more interesting, we can contaminate the data slightly,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1]\n",
      " [1 0 1 1]\n",
      " [0 0 1 1]\n",
      " [0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "M[1,0]=1 # put in different class\n",
    "print(M) # now contaminated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a `1` entry in the previously\n",
    "pure first column's second  row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,j = np.where(M==0)\n",
    "x=np.vstack([i,j]).T\n",
    "y = j.reshape(-1,1)*0\n",
    "i,j = np.where(M==1)\n",
    "x=np.vstack([np.vstack([i,j]).T,x])\n",
    "y = np.vstack([j.reshape(-1,1)*0+1,y])\n",
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is shown\n",
    "in [Figure](#fig:example_tree_002). Note the tree has grown\n",
    "significantly due to this one change! The $0^{th}$ node has the\n",
    "following parameters, $p_{0,0} =7/16$ and $p_{0,1}=9/16$. This makes\n",
    "the Gini coefficient for the $0^{th}$ node equal to\n",
    "$\\frac{7}{16}\\left(1-\\frac{7}{16}\\right)+\\frac{9}{16}(1-\\frac{9}{16})\n",
    "= 0.492$.  As before, the root node splits on $X[1] \\leq 1.5$. Let's\n",
    "see if we can reconstruct the succeeding layer of nodes manually, as\n",
    "in the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[x[:,1]>1.5] # first node on the right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This obviously has a zero Gini coefficient. Likewise, the node on the\n",
    "left contains the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "11"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[x[:,1]<=1.5] # first node on the left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gini coefficient in this case is computed as\n",
    "`(1/8)*(1-1/8)+(7/8)*(1-7/8)=0.21875`. This node splits based on `X[1]<0.5`.\n",
    "The child node to the right derives from the following equivalent logic,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True, False,  True, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logical_and(x[:,1]<=1.5,x[:,1]>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with corresponding classes,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[np.logical_and(x[:,1]<=1.5,x[:,1]>0.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Programming Tip.**\n",
    "\n",
    "The  `logical_and` in Numpy provides element-wise logical conjuction. It is not\n",
    "possible to accomplish this with something like `0.5< x[:,1] <=1.5` because\n",
    "of the way Python parses this syntax.\n",
    "\n",
    "\n",
    "\n",
    "<!-- dom:FIGURE: [fig-machine_learning/example_tree_002.png, width=500\n",
    "frac=0.65] Decision tree for contaminated data. Note that just one change in the\n",
    "training data caused the tree to grow five times as large as before! <div\n",
    "id=\"fig:example_tree_002\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:example_tree_002\"></div>\n",
    "\n",
    "<p>Decision tree for contaminated data. Note that just one change in the\n",
    "training data caused the tree to grow five times as large as before!</p>\n",
    "<img src=\"fig-machine_learning/example_tree_002.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "Notice that for this example as well as for the previous one, the decision tree\n",
    "was exactly able memorize (overfit) the data with perfect accuracy. From our\n",
    "discussion of machine learning theory, this is an indication potential problems\n",
    "in generalization.\n",
    "\n",
    "\n",
    "The key step in building the decision tree is to come up with the\n",
    "initial split. There are the number of algorithms that can build\n",
    "decision trees based on different criteria, but the general idea is to\n",
    "control the information *entropy* as the tree is developed.  In\n",
    "practical terms, this means that the algorithms attempt to build trees\n",
    "that are not excessively deep. It is well-established that this is a\n",
    "very hard problem to solve completely and there are many approaches to\n",
    "it.  This is because the algorithms must make global decisions at each\n",
    "node of the tree using the local data available up to that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "14"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d68127be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=clf.fit(x,y)\n",
    "fig,axs=subplots(2,2,sharex=True,sharey=True)\n",
    "ax=axs[0,0]\n",
    "ax.set_aspect(1)\n",
    "_=ax.axis((-1,4,-1,4))\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# same background all on axes\n",
    "for ax in axs.flat:\n",
    "    _=ax.plot(ma.masked_array(x[:,1],y==1),ma.masked_array(x[:,0],y==1),'ow',mec='k')\n",
    "    _=ax.plot(ma.masked_array(x[:,1],y==0),ma.masked_array(x[:,0],y==0),'o',color='gray')\n",
    "\n",
    "lines={'h':[],'v':[]}\n",
    "nc=0\n",
    "for i,j,ax in zip(clf.tree_.feature,clf.tree_.threshold,axs.flat):\n",
    "    _=ax.set_title('node %d'%(nc))\n",
    "    nc+=1\n",
    "    if i==0:   _=lines['h'].append(j)\n",
    "    elif i==1: _=lines['v'].append(j)\n",
    "    for l in lines['v']: _=ax.vlines(l,-1,4,lw=3)\n",
    "    for l in lines['h']: _=ax.hlines(l,-1,4,lw=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:FIGURE: [fig-machine_learning/example_tree_003.png, width=500\n",
    "frac=0.85]  The decision tree divides the training set into regions by splitting\n",
    "successively along each dimension until each region is as pure as possible. <div\n",
    "id=\"fig:example_tree_003\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:example_tree_003\"></div>\n",
    "\n",
    "<p>The decision tree divides the training set into regions by splitting\n",
    "successively along each dimension until each region is as pure as possible.</p>\n",
    "<img src=\"fig-machine_learning/example_tree_003.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "For this example, the decision tree partitions the $\\mathcal{X}$ space into\n",
    "different regions corresponding to different $\\mathcal{Y}$ labels as shown in\n",
    "[Figure](#fig:example_tree_003). The root node at the top of\n",
    "[Figure](#fig:example_tree_002) splits the input data based on $X[1] \\leq 1.5$.\n",
    "This\n",
    "corresponds to the top left panel in [Figure](#fig:example_tree_003) (i.e.,\n",
    "`node 0`) where the vertical line divides the training data shown into two\n",
    "regions, corresponding to the two subsequent child nodes. The next split\n",
    "happens with $X[1] \\leq 0.5$ as shown in the next panel of\n",
    "[Figure](#fig:example_tree_003) titled `node 1`. This continues until the last\n",
    "panel\n",
    "on the lower right, where the contaminated element we injected has been\n",
    "isolated into its own sub-region. Thus, the last panel is a representation of\n",
    "[Figure](#fig:example_tree_002), where the horizontal/vertical lines\n",
    "correspond to successive splits in the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAGwpJREFUeJzt3W9oW+t9B/DvT3+sCMlmL+btKkeF\njrG1u5TtiiUmst6sjju0rdnY8KBFW8CeyQtto4OO0qJXG+ht6RsLdpPaJcxbWbyVLetQ4+u0lAlR\nO3e67XpJC6UUJlnOdSlDjuzo728vbGdO4kRH0qNznuj5fSA0bnSOvsmVvz5/nuc5xMwQQpjL43YA\nIYS7pASEMJyUgBCGkxIQwnBSAkIYTkpACMMNVQJE9MdE9D4RdYnokqpQQgjnDHsk8H0AfwTg2wqy\nCCFc4BtmY2Z+CABEpCaNEMJxQ5VAP4joBoAbABAKhX7zox/9qFNv7Yjd3d2nv7948aKLSf6fbpkk\nj3PefffdnzLztJ3XUq9hw0T0DoA3zvmjDDP/68lrvgXgr5n5gZ03vXTpEj94YOulr42zR0O6DMXW\nLZPkcQ4RvcvMtq7T9TwSYOb54SMJIXQltwiFMNywtwj/kIjKAOIAvk5E31ATSwjhlGHvDnwNwNcU\nZRFCuEBOB4QwnJSAEIaTEhDCcFICQhhOSkAIw0kJCGE4KQEhDCclIIThpASEMJyUgBCGkxIQwnBS\nAkIYTkpACMNJCQhhOCkBIQwnJSCE4aQEhDCclIAQhpMSEMJwUgJCGE5KQAjDSQkIYTgpASEM59gD\nSXXDzCiXy6hUKmg0GggEArAsC9Fo1JWnLDMzisUitre3cXBwgMnJSczMzCAej7v21GfdMkme0ej5\nQNJRcPOBpJ1OB6VSCYVCAfV6Hd1uF51OB16vFx6PB6FQCIlEArFYDF6v1/Z+B324ZavVwurqKnK5\nHI6OjpBMJjE1NYVarYZ8Po9gMIh0Oo2lpSX4/f6+/q66ZZI8zunngaRGlUCz2cT6+jqq1SpardZL\nX+f3+xGJRJBKpTAxMWFr34N8oB4/foyFhQU0Gg1kMhnMzc3B4/n/M7Rut4utrS1ks1lcuHABGxsb\nCIfDtvatYybJ4xwpgXN0Oh3cvn0blUoFnU6n5+u9Xi8sy8L169dtHRH0+4FqtVq4du0aIpEIbt68\nCZ/v5Wdm7XYby8vL2Nvbw927d23/dNEtk+RxTj8loOTCIBElieiHRPQjIvq8in2qViqVUK1WbRUA\ncFwa1WoVpVJpJHlWV1fRaDR6fpgAwOfz4datW3jy5AnW1tZGkkfHTJLHGUOXABF5AawA+B0AbwL4\nNBG9Oex+VWJmFAqFV54CnKfVaqFQKPR1vmg3Ty6XQyaT6flhOuXz+ZDJZLCysqI8j46ZJI9zVBwJ\nzAD4ETP/mJmbAL4K4A8U7FeZcrmMer0+0Lb1eh3lcllpnmKxiKOjI8zNzfW13dWrV3F4eIhisag0\nj46ZJI9zVJSABeB/znxdPvn/tFGpVNDtdgfattvtolKpKM2zvb2NZDL5zAUlOzweD5LJJHZ2dpTm\n0TGT5HGOihI474boC8c+RHSDiB4Q0YP9/X0Fb2tfo9GwfS3geZ1OB81mU2meg4MDTE1NDbTt1NQU\nDg4OlOYB9MskeZyjogTKAD505usogN3nX8TMbzPzJWa+ND09reBt7QsEAn3d8z/L6/Xavk1o1+Tk\nJGq12kDb1mo1TE5OKs0D6JdJ8jhHRQnsAPgVIvolIpoA8CkA/6Zgv8pYltX3Ydwpj8cDy1J7djMz\nM4N8Pt/3KUq320U+n8fly5eV5tExk+RxztAlwMxtAH8B4BsAHgL4J2Z+f9j9qhSNRhEKhQbaNhwO\nIxqNKs0Tj8cRDAZx//79vrbb2tpCKBRCPB5XmkfHTJLHOUrGCTDzfzDzrzLzLzNzVsU+VSIiJBKJ\nvgds+P1+zM7OKh8HTkRIp9PIZrNot9u2tmm328hms0in0yMZl65bJsnjHGNmEcZiMUQiEdvXBrxe\nLyKRCGKx2EjyLC0tIRAIYHl5ueeH6nT0WTAYxOLi4kjy6JhJ8jjDmBLwer1IpVKwLKvnEYHf74dl\nWUilUgNfUOzF7/djY2MDe3t7mJ+fx+bm5gvnm91uF/fu3cP8/DwePXqEO3fujHT4qW6ZJI8zjJk7\ncKrXLMJwOIzZ2VlHZxGura1hZWUFh4eHL8xIC4VCSKfTWFxcdHQW4SgySR7nyAQiG86uJ9BsNjEx\nMTHUegKDfqDOblMsFrGzs/PM3PQrV64MfD6pWybJ4xwpARcM+4EaBd0ySR7nOD6LUAjx+pISEMJw\nUgJCGE5KQAjDSQkIYTgpASEMJyUghOFcefjI7u6u64MpRknHv5tumSSPPuRIQAjDSQkIYThXTgcu\nXryI3d0XViB7rek4BFW3TJLHOf2c3siRgBCGkxIQwnBSAkIYTkpACMNJCQhhOCkBIQwnJSCE4VwZ\nJ6CDs2sMNhoNBAKBodYYHLc8p5mKxSK2t7efWUMvHo+79m8kedQzrgR6rTYcCoWQSCT6Xm14XPIA\nx6vprq6uIpfL4ejo6Olquvv7+8jlcggGg0in01haWnJkNV3JM1pGLTTabDaxvr6OarWKVqv10tf5\n/X5EIhGkUinbDyMdZPTZKPMMmunx48dYWFhAo9FAJpPB3NzcM89x7Ha72NraQjabxYULF7CxsYFw\nOCx5FORRSVYbPken08Ht27dRqVRsPabc6/XCsixcv37d1k/gfj9Qo84zSKZWq4Vr164hEong5s2b\n8PlefqB4+oSdvb093L1719ZPPMnjHFlt+BylUgnVatXWNxxw/E1arVZRKpWMyAMAq6uraDQaPT/g\nAODz+XDr1i08efIEa2trkseFPKooKQEiWiWiD4jo+yr2pxozo1AovPKQ+zytVguFQkH55BLd8pxm\nyuVyyGQyPT/gp3w+HzKZDFZWVkbybyR5nKHqSOArAJKK9qVcuVxGvV4faNt6vY5yuTzWeQCgWCzi\n6OgIc3NzfW139epVHB4eolgsSh4H86ik6tHk3wbwMxX7GoVKpfLCgyPt6na7qFQqY50HALa3t5FM\nJp+5yGWHx+NBMpnEzs6O5HEwj0qOXRMgohtE9ICIHuzv7zv1tgCARqNh+9z7eZ1OB81mc6zzAMDB\nwQGmpqYG2nZqagoHBweSx8E8KjlWAsz8NjNfYuZL09PTTr0tACAQCAx8j93r9fZ1W+51zAMAk5OT\nqNVqA21bq9UwOTkpeRzMo5IRdwcsy+r7MO6Ux+OBZVljnQcAZmZmkM/n+z5N6Xa7yOfzuHz5suRx\nMI9KRpRANBpFKBQaaNtwOIxoNDrWeQAgHo8jGAzi/v37fW23tbWFUCiEeDwueRzMo5KqW4T/CKAI\n4CNEVCaiP1OxX1WICIlEou8BG36/H7Ozs8rHgeuW5zRTOp1GNptFu922tU273UY2m0U6nR7Jv5Hk\ncYaquwOfZuYIM/uZOcrMX1axX5VisRgikYjtc3Gv14tIJIJYLGZEHgBYWlpCIBDA8vJyzw/66Yi4\nYDCIxcVFyeNCHlWMOB0Ajr+JUqkULMvq+RPY7/fDsiykUqmRTdrRLc/p+2xsbGBvbw/z8/PY3Nx8\n4Ry42+3i3r17mJ+fx6NHj3Dnzp2RDYmVPM4wZu7AqV6z9sLhMGZnZ/uetTfo8tWjyjNMplarhbW1\nNaysrODw8PDpLLlarYZ8Po9QKIR0Oo3FxcW+PuCSxzkygciGs/P3m80mJiYmhpq/P+wa9qrzqMpU\nLBaxs7PzzHz5K1euuPZvNM55VJIScIGOD7LQLZPkcY7MIhRC2CYlIIThpASEMJyUgBCGkxIQwnBS\nAkIYTkpACMO58tyB3d1d1wdTjJKOfzfdMkkefciRgBCGkxIQwnCunA5cvHgRu7u7brz1yOg4BFW3\nTJLHOf2c3siRgBCGkxIQwnBSAkIYTkpACMNJCQhhOCkBIQwnJSCE4VwZJ6CDs2v6NRoNBAKBodf0\nG6c8OmY6XdNve3v7mTX94vG45BmCcSXQa3XfUCiERCIx0Oq+45BHx0ytVgurq6vI5XI4Ojp6urrv\n/v4+crkcgsEg0uk0lpaWHFndV7c8wzJqodFms4n19XVUq1W0Wq2Xvs7v9yMSiSCVStl++Ocgo89G\nmUfHTIPkefz4MRYWFtBoNJDJZDA3N/fMcxy73S62traQzWZx4cIFbGxsIBwOv5Z5VJLVhs/R6XRw\n+/ZtVCoVW48F93q9sCwL169ft/XTrt8P1Kjz6Jip3zytVgvXrl1DJBLBzZs34fO9/MD19Ik/e3t7\nuHv3rq2fwLrlUUlWGz5HqVRCtVq19eEGjr8hqtUqSqWSEXl0zLS6uopGo9HzGw4AfD4fbt26hSdP\nnmBtbc2IPKoMXQJE9CEi+iYRPSSi94noMyqCqcTMKBQKrzy8PU+r1UKhUFA+uUS3PDpmYmbkcjlk\nMpme33CnfD4fMpkMVlZWxj6PSiqOBNoAPsvMvwbgCoA/J6I3FexXmXK5jHq9PtC29Xod5XJ5rPMA\n+mUqFos4OjrC3NxcX9tdvXoVh4eHKBaLY51HpaFLgJmrzPxfJ78/APAQgDXsflWqVCovPDjSrm63\ni0qlMtZ5AP0ybW9vI5lMPnPRzQ6Px4NkMomdnZ2xzqOS0msCRPRhADEA3znnz24Q0QMierC/v6/y\nbXtqNBq2z3Of1+l00Gw2xzoPoF+mg4MDTE1NDbTt1NQUDg4OxjqPSspKgIjCAP4ZwF8xc+35P2fm\nt5n5EjNfmp6eVvW2tgQCgYHvZ3u93r5uy72OeQD9Mk1OTqJWe+FjZEutVsPk5ORY51FJSQkQkR/H\nBbDOzP+iYp8qWZbV92HcKY/HA8tSe3ajWx5Av0wzMzPI5/N9n6J0u13k83lcvnx5rPOopOLuAAH4\nMoCHzPzF4SOpF41GEQqFBto2HA4jGo2OdR5Av0zxeBzBYBD379/va7utrS2EQiHE4/GxzqOSiiOB\nBIA/BTBHRO+d/PpdBftVhoiQSCT6HrDh9/sxOzurfBy4bnl0zERESKfTyGazaLfbtrZpt9vIZrNI\np9Njn0clFXcH/pOZiZl/nZnfOvn1HyrCqRSLxRCJRGyf93q9XkQiEcRiMSPy6JhpaWkJgUAAy8vL\nPb/xTkfoBYNBLC4uGpFHFWNGDHq9XqRSKViW1fOnnd/vh2VZSKVSI5sgo1seHTP5/X5sbGxgb28P\n8/Pz2NzcfOGcvNvt4t69e5ifn8ejR49w586dkQ3R1S2PKsbMHTjVa4ZcOBzG7Oxs3zPkBl2+elR5\ndMw0aJ5Wq4W1tTWsrKzg8PDw6ay9Wq2GfD6PUCiEdDqNxcXFvr7hdMujkkwgsuHsXPlms4mJiYmh\n5soPu4a96jw6ZlKRp1gsYmdn55n5+1euXBmLPCpJCbhAxwdZ6JZJ8jhHZhEKIWyTEhDCcFICQhhO\nSkAIw0kJCGE4KQEhDCclIIThXHnuwO7uruuDKUZJx7+bbpkkjz7kSEAIw0kJCGE4V04HLl68iN3d\nXTfeemR0HIKqWybJ45x+Tm/kSEAIw0kJCGE4KQEhDCclIIThpASEMJyUgBCGkxIQwnCujBPQwdn1\n8xqNBgKBwNBr+o1THh0z6ZinWCxie3v7mTUG4/H4azUM2bgS6LWSbigUQiKRGGh133HIo2Mm3fK0\nWi2srq4il8vh6Ojo6WrD+/v7yOVyCAaDSKfTWFpa0n65ccCwhUabzSbW19dRrVbRarVe+jq/349I\nJIJUKmX7QZuDjD4bZR4dM41DnsePH2NhYQGNRgOZTAZzc3PPPMOx2+1ia2sL2WwWFy5cwMbGBsLh\nsK19qyQLjZ6j0+lgfX0dlUrllR8m4LjpK5UK1tfXB35c9+uWR8dMuuVptVpYWFhAJBLB5uYm5ufn\nX3iIq8fjwSc+8Qm88847eOONN7CwsNAzu9uMKYFSqYRqtWr7A9LpdFCtVlEqlYzIo2Mm3fKsrq6i\n0Wjg5s2b8PlefSbt8/lw69YtPHnyBGtrayPJo4qKpxJfIKJtIvouEb1PRH+jIphKzIxCodB3I7da\nLRQKBeWTS3TLo2MmHfPkcjlkMpmeBXDK5/Mhk8lgZWVF6wlKKo4EGgDmmPk3ALwFIElEVxTsV5ly\nuYx6vT7QtvV6HeVyeazzAPpl0i1PsVjE0dER5ubm+tru6tWrODw8RLFYVJpHJRVPJWZmfnzypf/k\nl1a1V6lUXnhwpF3dbheVSmWs8wD6ZdItz/b2NpLJ5AvXAHrxeDxIJpPY2dlRmkclJdcEiMhLRO8B\n+ADAJjN/55zX3CCiB0T0YH9/X8Xb2tZoNAa+WNTpdNBsNsc6D6BfJt3yHBwcYGpqaqBtp6amcHBw\noDSPSkpKgJk7zPwWgCiAGSL62DmveZuZLzHzpenpaRVva1sgEBj4/rHX6+3rttzrmAfQL5NueSYn\nJ1Gr1QbatlarYXJyUmkelZTeHWDm/wXwLQBJlfsdlmVZfR/GnfJ4PLAsa6zzAPpl0i3PzMwM8vl8\n36co3W4X+Xwely9fVppHJRV3B6aJ6OdOfh8EMA/gB8PuV6VoNIpQKDTQtuFwGNFodKzzAPpl0i1P\nPB5HMBjE/fv3+9pua2sLoVAI8XhcaR6VVBwJRAB8k4i+B2AHx9cE/l3BfpUhIiQSib6HcPr9fszO\nziofB65bHh0z6ZgnnU4jm82i3W7b2qbdbiObzSKdTms9l0DF3YHvMXOMmX+dmT/GzH+rIphqsVgM\nkUjE9nmm1+tFJBJBLBYzIo+OmXTLs7S0hEAggOXl5Z5F0G63sby8jGAwiMXFxZHkUcWYEYNerxep\nVAqWZfX86eL3+2FZFlKp1MgmpOiWR8dMuuXx+/3Y2NjA3t4e5ufnsbm5+cI1gm63i3v37mF+fh6P\nHj3CnTt3tJ9EZNQEIqD3jLRwOIzZ2dm+Z6QNunz1qPLomGlc8rRaLaytrWFlZQWHh4dPZxHWajXk\n83mEQiGk02ksLi66VgD9TCAyrgROnZ2b3mw2MTExMdTc9GHXsFedR8dM45inWCxiZ2fnmfUErly5\n4vo1ACkBF+j4IAvdMkke58hUYiGEbVICQhhOSkAIw0kJCGE4KQEhDCclIIThpASEMJwrzx3Y3d11\nfTDFKOn4d9Mtk+TRhxwJCGE4KQEhDOfK6cDFixexu7vrxluPjI5DUHXLJHmc08/pjRwJCGE4KQEh\nDCclIIThpASEMJyUgBCGkxIQwnBSAkIYTkpACMO5MlhIB2cXrWw0GggEAkMv7DlOeXTMJHlGw7gS\n6LV8dSgUQiKRGGiJ73HIo2MmyTNaRq023Gw2sb6+jmq1ilar9dLX+f1+RCIRpFIp20+3HWQI6ijz\n6JhJ8jhHVhs+R6fTwfr6OiqVyiv/4wHHD5eoVCpYX19Hp9MxIo+OmSSPM5SVABF5iahERFo9jPRU\nqVRCtVq1/R+k0+mgWq2iVCoZkUfHTJLHGSqPBD4D4KHC/SnDzCgUCj3b+3mtVguFQkH5DDPd8uiY\nSfI4R0kJEFEUwO8BuKVif6qVy2XU6/WBtq3X6yiXy2OdB9Avk+RxjqojgS8B+ByAbq8XuqFSqbzw\n9Fi7ut0uKpXKWOcB9MskeZwzdAkQ0ScBfMDM7/Z43Q0iekBED/b394d92740Go2BL850Oh00m82x\nzgPol0nyOEfFkUACwO8T0U8AfBXAHBH9/fMvYua3mfkSM1+anp5W8Lb2BQKBge/Xer1e5bd4dMsD\n6JdJ8jhn6BJg5i8wc5SZPwzgUwDuM/OfDJ1MIcuy4PEM9lf1eDywLGus8wD6ZZI8zjFinEA0GkUo\nFBpo23A4jGg0OtZ5AP0ySR7nKC0BZv4WM39S5T5VICIkEgn4/f6+tvP7/ZidnVU+Dly3PDpmkjzO\nMeJIAABisRgikYjt8zqv14tIJIJYLGZEHh0zSR5nGFMCXq8XqVQKlmX1bHO/3w/LspBKpUY2AUS3\nPDpmkjzOMGoCEdB7Blg4HMbs7GzfM8AGXcN+VHl0zCR5nNPPBCLjSuDU2bngzWYTExMTQ80FH/ZB\nFqrz6JhJ8jhHSsAFOj7NRrdMksc5MpVYCGGblIAQhpMSEMJwUgJCGE5KQAjDSQkIYTgpASEMJyUg\nhOGkBIQwnJSAEIaTEhDCcFICQhhOSkAIw0kJCGE4KQEhDCclIIThpASEMJyUgBCGkxIQwnBSAkIY\nTkpACMNJCQhhOCkBIQznU7ETIvoJgAMAHQBtu+udCyHcp6QETnycmX+qcH9CCAfI6YAQhlN1JMAA\n7hERA/g7Zn77+RcQ0Q0AN06+bBDR9xW9two/D0DZUYyC59ApzQPol0nyjNxH7L5QybMIiegiM+8S\n0S8A2ATwl8z87Ve8/oFO1w0kT2+6ZZI8r9ZPHiWnA8y8e/K/HwD4GoAZFfsVQoze0CVARCEimjz9\nPYDfBqDTob4Q4hVUXBP4RQBfOzmn8gH4B2bO99jmhWsGLpM8vemWSfK8mu08Sq4JCCFeX3KLUAjD\nSQkIYTjXSoCI/piI3ieiLhG5dmuFiJJE9EMi+hERfd6tHCdZVonoA13GUBDRh4jom0T08OS/1Wc0\nyHSBiLaJ6Lsnmf5Gg0xeIioR0b+7nQU4HsZPRP9NRO8R0YNer3fzSOD7AP4IwEvHE4waEXkBrAD4\nHQBvAvg0Eb3pVh4AXwGQdPH9n9cG8Flm/jUAVwD8ucv/PgDQADDHzL8B4C0ASSK64nKmzwB46HKG\n532cmd+yM1bAtRJg5ofM/EO33v/EDIAfMfOPmbkJ4KsA/sCtMCcDrH7m1vs/j5mrzPxfJ78/wPEH\n3XI5EzPz45Mv/Se/XLu6TURRAL8H4JZbGYZl+jUBC8D/nPm6DJc/5Loiog8DiAH4jrtJnh5+vwfg\nAwCbzOxmpi8B+ByArosZnnc6jP/dk+H6r6RyFuELiOgdAG+c80cZZv7XUb63TecNGJd7ps8hojCA\nfwbwV8xcczsPM3cAvEVEP4fjMSofY2bHr6MQ0ScBfMDM7xLRbzn9/q+QODuMn4h+8Kph/CMtAWae\nH+X+FSgD+NCZr6MAdl3KoiUi8uO4ANaZ+V/cznMWM/8vEX0Lx9dR3LiYmgDw+0T0uwAuAJgior9n\n5j9xIctTZ4fxE9HpMP6XloDppwM7AH6FiH6JiCYAfArAv7mcSRt0PAz0ywAeMvMX3c4DAEQ0fXIE\nACIKApgH8AM3sjDzF5g5yswfxvFn577bBTDIMH43bxH+IRGVAcQBfJ2IvuF0BmZuA/gLAN/A8UWv\nf2Lm953OcYqI/hFAEcBHiKhMRH/mVpYTCQB/CmDu5HbTeyc/9dwUAfBNIvoejkt8k5m1uDWniV8E\n8J9E9F0A2wC+3msYvwwbFsJwpp8OCGE8KQEhDCclIIThpASEMJyUgBCGkxIQwnBSAkIY7v8APaz8\nbHmrTR8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d3309de80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i,j = np.indices((5,5))\n",
    "x=np.vstack([i.flatten(),j.flatten()]).T\n",
    "y=(x[:,0]>=x[:,1]).astype(int).reshape((-1,1))\n",
    "_=clf.fit(x,y)\n",
    "fig,ax=subplots()\n",
    "_=ax.axis((-1,5,-1,5))\n",
    "ax.set_aspect(1)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "_=ax.plot(ma.masked_array(x[:,1],y==1),ma.masked_array(x[:,0],y==1),'ow',mec='k',ms=15)\n",
    "_=ax.plot(ma.masked_array(x[:,1],y==0),ma.masked_array(x[:,0],y==0),'o',color='gray',ms=15)\n",
    "\n",
    "for i,j in zip(clf.tree_.feature,clf.tree_.threshold):\n",
    "    if i==1:\n",
    "        _=ax.hlines(j,-1,6,lw=3.)\n",
    "    else:\n",
    "        _=ax.vlines(j,-1,6,lw=3.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:FIGURE: [fig-machine_learning/example_tree_004.png, width=500\n",
    "frac=0.75]  The decision tree fitted to this triangular matrix is very complex,\n",
    "as shown by the number of horizontal and vertical partitions. Thus, even though\n",
    "the pattern in the training data is visually clear, the decision tree cannot\n",
    "automatically uncover it. <div id=\"fig:example_tree_004\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:example_tree_004\"></div>\n",
    "\n",
    "<p>The decision tree fitted to this triangular matrix is very complex, as shown\n",
    "by the number of horizontal and vertical partitions. Thus, even though the\n",
    "pattern in the training data is visually clear, the decision tree cannot\n",
    "automatically uncover it.</p>\n",
    "<img src=\"fig-machine_learning/example_tree_004.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "[Figure](#fig:example_tree_004) shows another example, but now using a simple\n",
    "triangular matrix.  As shown by the number of vertical and horizontal\n",
    "partitioning lines, the decision tree that corresponds to this figure is tall\n",
    "and complex. Notice that if we apply a simple rotational transform to the\n",
    "training data, we can obtain [Figure](#fig:example_tree_005), which requires a\n",
    "trivial decision tree to fit. Thus, there may be transformations of the\n",
    "training data that simplify the decision tree, but these are very difficult to\n",
    "derive in general. Nonetheless, this highlights a key weakness of decision\n",
    "trees wherein they may be easy to understand, to train, and to deploy, but may\n",
    "be completely blind to such time-saving and complexity-saving transformations.\n",
    "Indeed, in higher dimensions, it may be impossible to even visualize the\n",
    "potential of such latent transformations.  Thus, the advantages of decision\n",
    "trees can be easily outmatched by other methods that we will study later that\n",
    "*do* have the ability to uncover useful transformations, but which will\n",
    "necessarily be harder to train.  Another disadvantage is that because of how\n",
    "decision trees are built, even a single misplaced data point can cause the tree\n",
    "to grow very differently. This is a symptom of high variance.\n",
    "\n",
    "In all of our examples, the decision tree was able to memorize the training\n",
    "data exactly, as we discussed earlier, this is a sign of potential\n",
    "generalization errors.  There are pruning algorithms that strategically remove\n",
    "some of the deepest nodes. but these are not yet fully implemented in\n",
    "Scikit-learn, as of this writing. Alternatively, restricting the maximum depth\n",
    "of the decision tree can have a similar effect. The `DecisionTreeClassifier`\n",
    "and `DecisionTreeRegressor` in Scikit-learn both have keyword arguments that\n",
    "specify maximum depth.\n",
    "\n",
    "## Random Forests\n",
    "\n",
    "It is possible to combine a set of decision trees into a larger\n",
    "composite tree that has better performance than its individual\n",
    "components by using ensemble learning. This is implemented in\n",
    "Scikit-learn as `RandomForestClassifier`.  The composite tree helps\n",
    "mitigate the primary weakness of decision trees --- high variance.\n",
    "Random forest classifiers help by averaging out the predictions of\n",
    "many constituent trees to minimize this variance by randomly selecting\n",
    "subsets of the training set to train the  embedded trees.   On the\n",
    "other hand, this randomization can increase bias because there may be\n",
    "a subset of the training set that yields an excellent decision tree,\n",
    "but the averaging effect over randomized training samples washes this\n",
    "out in the same averaging that reduces the variance. This is a key\n",
    "trade-off.  The following code implements a simple random forest\n",
    "classifer from our last example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "16"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARwAAAD8CAYAAAClxxvWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d330352e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import sin, cos, pi\n",
    "rotation_matrix=np.matrix([[cos(pi/4),-sin(pi/4)],\n",
    "                           [sin(pi/4),cos(pi/4)]])\n",
    "xr=(rotation_matrix*(x.T)).T\n",
    "xr=np.array(xr)\n",
    "\n",
    "fig,ax=subplots()\n",
    "ax.set_aspect(1)\n",
    "_=ax.axis(xmin=-2,xmax=7,ymin=-4,ymax=4)\n",
    "\n",
    "_=ax.plot(ma.masked_array(xr[:,1],y==1),ma.masked_array(xr[:,0],y==1),'ow',mec='k',ms=15)\n",
    "_=ax.plot(ma.masked_array(xr[:,1],y==0),ma.masked_array(xr[:,0],y==0),'o',color='gray',ms=15)\n",
    "\n",
    "_=clf.fit(xr,y)\n",
    "\n",
    "for i,j in zip(clf.tree_.feature,clf.tree_.threshold):\n",
    "    if i==1:\n",
    "        _=ax.vlines(j,-1,6,lw=3.)\n",
    "    elif i==0:\n",
    "        _=ax.hlines(j,-1,6,lw=3.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:FIGURE: [fig-machine_learning/example_tree_005.png, width=500\n",
    "frac=0.75] Using a simple rotation on the training data in\n",
    "[Figure](#fig:example_tree_004), the decision tree can now easily fit the\n",
    "training data with a single partition. <div id=\"fig:example_tree_005\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:example_tree_005\"></div>\n",
    "\n",
    "<p>Using a simple rotation on the training data in\n",
    "[Figure](#fig:example_tree_004), the decision tree can now easily fit the\n",
    "training data with a single partition.</p>\n",
    "<img src=\"fig-machine_learning/example_tree_005.png\" width=500>\n",
    "\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "17"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda2/envs/py3/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,random_state=1)\n",
    "clf = tree.DecisionTreeClassifier(max_depth=2)\n",
    "_=clf.fit(X_train,y_train)\n",
    "rfc = RandomForestClassifier(n_estimators=4,max_depth=2)\n",
    "_=rfc.fit(X_train,y_train.flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "18"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=4, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=4,max_depth=2)\n",
    "rfc.fit(X_train,y_train.flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "19"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_board(x,y,clf,ax=None):\n",
    "    if ax is None: fig,ax=subplots()\n",
    "    xm,ymn=x.min(0).T\n",
    "    ax.axis(xmin=xm-1,ymin=ymn-1)\n",
    "    xx,ymx=x.max(0).T\n",
    "    _=ax.axis(xmax=xx+1,ymax=ymx+1)\n",
    "    _=ax.set_aspect(1)\n",
    "    _=ax.invert_yaxis()\n",
    "    _=ax.plot(ma.masked_array(x[:,1],y==1),ma.masked_array(x[:,0],y==1),'ow',mec='k')\n",
    "    _=ax.plot(ma.masked_array(x[:,1],y==0),ma.masked_array(x[:,0],y==0),'o',color='gray')\n",
    "    for i,j in zip(clf.tree_.feature,clf.tree_.threshold):\n",
    "        if i==1:\n",
    "            _=ax.vlines(j,-1,6,lw=3.)\n",
    "        elif i==0:\n",
    "            _=ax.hlines(j,-1,6,lw=3.)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "20"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAD8CAYAAADjcbh8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNjgi8hYbHBF5iw2OiLzFBkdE3vp/TpwlQIX6rOIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d32a8d860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axs = subplots(2,2)\n",
    "# draw constituent decision trees\n",
    "for est,ax in zip(rfc.estimators_,axs.flat):\n",
    "    _=draw_board(X_train,y_train,est,ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have constrained the maximum depth `max_depth=2` to help\n",
    "with generalization. To keep things simple we have only set up a forest with\n",
    "four individual classifers [^seedNote].  [Figure](#fig:example_tree_006) shows\n",
    "the individual classifers in the forest that have been trained above. Even\n",
    "though all the constituent decision trees share the same training data, the\n",
    "random forest  algorithm randomly picks feature subsets (with replacement) upon\n",
    "which to train individual trees. This helps avoid the tendency of decision\n",
    "trees to become too deep and lopsided, which hurts both performance and\n",
    "generalization. At the prediction step, the individual outputs of each of the\n",
    "constituent decision trees are put to a majority vote for the final\n",
    "classification. To estimate generalization errors without using\n",
    "cross-validation, the training elements *not* used for a particular constituent\n",
    "tree can be used to test that tree and form a collaborative estimate of\n",
    "generalization errors.  This is called the *out-of-bag* estimate.\n",
    "\n",
    "[^seedNote]: We have also set the random seed to a fixed value\n",
    "to make the figures reproducible in the IPython Notebook corresponding to\n",
    "this section.\n",
    "\n",
    "<!-- dom:FIGURE: [fig-machine_learning/example_tree_006.png, width=500\n",
    "frac=0.85] The constituent decision trees of the random forest and how they\n",
    "partitioned the training set are shown in these four panels. The random forest\n",
    "classifier uses the individual outputs of each of the constituent trees to\n",
    "produce a collaborative  final estimate. <div id=\"fig:example_tree_006\"></div>\n",
    "-->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:example_tree_006\"></div>\n",
    "\n",
    "<p>The constituent decision trees of the random forest and how they partitioned\n",
    "the training set are shown in these four panels. The random forest classifier\n",
    "uses the individual outputs of each of the constituent trees to produce a\n",
    "collaborative  final estimate.</p>\n",
    "<img src=\"fig-machine_learning/example_tree_006.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "The main advantage of random forest classifiers is that they require very\n",
    "little tuning and provide a way to trade-off bias and variance via averaging\n",
    "and randomization. Furthermore, they are fast and easy to train in parallel\n",
    "(see the `n_jobs` keyword argument) and fast to predict. On the downside, they\n",
    "are less interpretable than simple decision trees.  There are many other\n",
    "powerful tree methods in Scikit-learn like `ExtraTrees` and Gradient Boosted\n",
    "Regression Trees `GradientBoostingRegressor` which are discussed in the online\n",
    "documentation.\n",
    "\n",
    "<!-- TODO: [stochastic gradient trees and\n",
    "boosting](http://nbviewer.ipython.org/github/pprett/pydata-gbrt-\n",
    "tutorial/blob/master/gbrt-tutorial.ipynb) -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
