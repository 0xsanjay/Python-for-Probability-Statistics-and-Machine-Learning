{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "../../../python_for_probability_statistics_and_machine_learning.jpg",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image \n",
    "Image('../../../python_for_probability_statistics_and_machine_learning.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bernoulli distribution we studied earlier answers the question of which of\n",
    "two outcomes ($Y \\in \\lbrace 0,1 \\rbrace$) would be selected with probability,\n",
    "$p$.\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(Y) = p^Y (1-p)^{ 1-Y }\n",
    "$$\n",
    "\n",
    " We also know how to solve the corresponding likelihood function for\n",
    "the maximum likelihood estimate of $p$ given observations of the output,\n",
    "$\\lbrace Y_i \\rbrace_{i=1}^n$. However, now we want to include other factors in\n",
    "our estimate of $p$. For example, suppose we observe not just the outcomes, but\n",
    "a corresponding continuous variable, $x$. That is, the observed data is now\n",
    "$\\lbrace (x_i,Y_i) \\rbrace_{i=1}^n$  How can we incorporate $x$ into our\n",
    "estimation of $p$?\n",
    "\n",
    "The most straightforward idea is to model $p= a x + b$ where $a,b$ are\n",
    "parameters of a fitted line. However, because $p$ is a probability with value\n",
    "bounded between zero and one, we need to wrap this estimate in another function\n",
    "that can map the entire real line into the $[0,1]$ interval. The logistic\n",
    "(a.k.a. sigmoid) function has this property,\n",
    "\n",
    "$$\n",
    "\\theta(s) = \\frac{e^s}{1+e^s}\n",
    "$$\n",
    "\n",
    " Thus, the new parameterized estimate for $p$ is the following,\n",
    "\n",
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:prob\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{p} = \\theta(a x+b)= \\frac{e^{a x + b}}{1+e^{a x + b}}\n",
    "\\label{eq:prob} \\tag{1}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    " This is usually expressed using the *logit* function,\n",
    "\n",
    "$$\n",
    "\\texttt{logit}(t)= \\log \\frac{t}{1-t}\n",
    "$$\n",
    "\n",
    " as,\n",
    "\n",
    "$$\n",
    "\\texttt{logit}(p) = b + a x\n",
    "$$\n",
    "\n",
    " More continuous variables can be accommodated easily as\n",
    "\n",
    "$$\n",
    "\\texttt{logit}(p) = b + \\sum_k a_k x_k\n",
    "$$\n",
    "\n",
    " This can be further extended beyond the binary case to multiple\n",
    "target labels. The maximum likelihood estimate of this uses\n",
    "numerical optimization methods that are implemented in Scikit-learn.\n",
    "\n",
    "Let's construct some data to see how this works. In the following, we assign\n",
    "class labels to a set of randomly scattered points in the two-dimensional\n",
    "plane,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.pylab import subplots\n",
    "v = 0.9\n",
    "@np.vectorize\n",
    "def gen_y(x):\n",
    "    if x<5: return np.random.choice([0,1],p=[v,1-v]) \n",
    "    else:   return np.random.choice([0,1],p=[1-v,v])\n",
    "\n",
    "xi = np.sort(np.random.rand(500)*10)\n",
    "yi = gen_y(xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Programming Tip.**\n",
    "\n",
    "The `np.vectorize` decorator used in the code above makes it easy to avoid\n",
    "looping in code that uses Numpy arrays by embedding the looping semantics\n",
    "inside of the so-decorated function. Note, however, that this does not\n",
    "necessarily accelerate the wrapped function. It's mainly for convenience.\n",
    "\n",
    "\n",
    "\n",
    "[Figure](#fig:logreg_001) shows a scatter plot of the data we constructed in\n",
    "the above code, $\\lbrace (x_i,Y_i) \\rbrace$. As constructed, it is more\n",
    "likely that large values of $x$ correspond to $Y=1$. On the other hand, values\n",
    "of $x \\in [4,6]$ of either category are heavily overlapped. This means that $x$\n",
    "is not a particularly strong indicator of $Y$ in this region.\n",
    "[Figure](#fig:logreg_002) shows the fitted logistic regression curve against the\n",
    "same\n",
    "data. The points along the curve are the probabilities that each point lies in\n",
    "either of the two categories. For large values of $x$ the curve is near one,\n",
    "meaning that the probability that the associated $Y$ value is equal to one. On\n",
    "the other extreme, small values of $x$ mean that this probability is close to\n",
    "zero.  Because there are only two possible categories, this means that the\n",
    "probability of $Y=0$ is thereby higher. The region in the middle corresponding\n",
    "to the middle probabilities reflect the ambiguity between the two catagories\n",
    "because of the overlap in the data for this region. Thus, logistic regression\n",
    "cannot make a strong case for one category here.\n",
    "The following code fits the logistic regression model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEUCAYAAADTO7pnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCSYwkNERIIpPEREJNj/B7fooS5wBMjwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07381020b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=subplots()\n",
    "_=ax.plot(xi,yi,'o',color='gray',alpha=.3)\n",
    "_=ax.axis(ymax=1.1,ymin=-0.1)\n",
    "_=ax.set_xlabel(r'$X$',fontsize=22)\n",
    "_=ax.set_ylabel(r'$Y$',fontsize=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(np.c_[xi],yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAETCAYAAAAYm1C6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOjoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f070ef7fd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=subplots()\n",
    "xii=np.linspace(0,10,20)\n",
    "_=ax.plot(xii,lr.predict_proba(np.c_[xii])[:,1],'k-',lw=3)\n",
    "_=ax.plot(xi,yi,'o',color='gray',alpha=.3)\n",
    "_=ax.axis(ymax=1.1,ymin=-0.1)\n",
    "_=ax.set_xlabel(r'$x$',fontsize=20)\n",
    "_=ax.set_ylabel(r'$\\mathbb{P}(Y)$',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:FIGURE: [fig-machine_learning/logreg_001.png, width=500 frac=0.75]\n",
    "This scatterplot shows the binary $Y$ variables and the corresponding $x$ data\n",
    "for each category. <div id=\"fig:logreg_001\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:logreg_001\"></div>\n",
    "\n",
    "<p>This scatterplot shows the binary $Y$ variables and the corresponding $x$\n",
    "data for each category.</p>\n",
    "<img src=\"fig-machine_learning/logreg_001.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "<!-- dom:FIGURE: [fig-machine_learning/logreg_002.png, width=500 frac=0.75]\n",
    "This shows the fitted logistic regression on the data shown in\n",
    "[Figure](#fig:logreg_001). The points along the curve are the probabilities that\n",
    "each point lies in either of the two categories.  <div\n",
    "id=\"fig:logreg_002\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:logreg_002\"></div>\n",
    "\n",
    "<p>This shows the fitted logistic regression on the data shown in\n",
    "[Figure](#fig:logreg_001). The points along the curve are the probabilities that\n",
    "each point lies in either of the two categories.</p>\n",
    "<img src=\"fig-machine_learning/logreg_002.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "For a deeper understanding of logistic regression, we need to alter our\n",
    "notation slightly and once again use our projection methods. More generally we\n",
    "can rewrite Equation [eq:prob](#eq:prob) as the following,\n",
    "\n",
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:probbeta\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "p(\\mathbf{x}) = \\frac{1}{1+\\exp(-\\boldsymbol{\\beta}^T \\mathbf{x})}\n",
    "\\label{eq:probbeta} \\tag{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    " where $\\boldsymbol{\\beta}, \\mathbf{x}\\in \\mathbb{R}^n$.  From our\n",
    "prior work on projection we know that the signed perpendicular distance between\n",
    "$\\mathbf{x}$ and the linear boundary described by $\\boldsymbol{\\beta}$ is\n",
    "$\\boldsymbol{\\beta}^T \\mathbf{x}/\\Vert\\boldsymbol{\\beta}\\Vert$.  This means\n",
    "that the probability that is assigned to any point in $\\mathbb{R}^n$ is a\n",
    "function of how close that point is to the linear boundary described by the\n",
    "following equation,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\beta}^T \\mathbf{x} = 0\n",
    "$$\n",
    "\n",
    " But there is something subtle hiding here. Note that\n",
    "for any $\\alpha\\in\\mathbb{R}$,\n",
    "\n",
    "$$\n",
    "\\alpha\\boldsymbol{\\beta}^T \\mathbf{x} = 0\n",
    "$$\n",
    "\n",
    " describes the *same* hyperplane. This means that we can multiply\n",
    "$\\boldsymbol{\\beta}$ by an arbitrary scalar and still get the same geometry.\n",
    "However, because of $\\exp(-\\alpha\\boldsymbol{\\beta}^T \\mathbf{x})$ in Equation\n",
    "[eq:probbeta](#eq:probbeta), this scaling determines the intensity of the\n",
    "probability\n",
    "attributed to $\\mathbf{x}$. This is illustrated in [Figure](#fig:logreg_003).\n",
    "The panel on the left shows two categories (squares/circles) split by the\n",
    "dotted line that is determined by $\\boldsymbol{\\beta}^T\\mathbf{x}=0$. The\n",
    "background colors shows the probabilities assigned to points in the plane.  The\n",
    "right panel shows that by scaling with $\\alpha$, we can increase the\n",
    "probabilities of class membership for the given points, given the exact same\n",
    "geometry. The points near the boundary have lower probabilities because they\n",
    "could easily be on the opposite side.  However, by scaling by $\\alpha$, we can\n",
    "raise those probabilities to any desired level at the cost of driving the\n",
    "points further from the boundary closer to one. Why is this a problem? By\n",
    "driving the probabilities arbitrarily using $\\alpha$, we can overemphasize the\n",
    "training set at the cost of out-of-sample data. That is, we may wind up\n",
    "insisting on emphatic class membership of yet unseen points that are close to\n",
    "the boundary that otherwise would have more equivocal probabilities (say, near\n",
    "$1/2$).  Once again, this is another manifestation of bias/variance trade-off.\n",
    "\n",
    "<!-- dom:FIGURE: [fig-machine_learning/logreg_003.png, width=500 frac=1.25]\n",
    "Scaling can arbitrarily increase the probabilities of points near the decision\n",
    "boundary.   <div id=\"fig:logreg_003\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:logreg_003\"></div>\n",
    "\n",
    "<p>Scaling can arbitrarily increase the probabilities of points near the\n",
    "decision boundary.</p>\n",
    "<img src=\"fig-machine_learning/logreg_003.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "Regularization is a method that controls this effect by penalizing the size of\n",
    "$\\beta$ as part of its solution. Algorithmically, logistic regression works by\n",
    "iteratively solving a sequence of weighted least squares problems. Regression\n",
    "adds a $\\Vert\\boldsymbol{\\beta}\\Vert/C$ term to the least squares error. To see\n",
    "this in action, let's create some data from a logistic regression and see if we\n",
    "can recover it using Scikit-learn. Let's start with a scatter of points in the\n",
    "two-dimensional  plane,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0,x1=np.random.rand(2,20)*6-3\n",
    "X = np.c_[x0,x1,x1*0+1] # stack as columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `X` has a third column of all ones. This is a\n",
    "trick to allow the corresponding line to be offset from the origin\n",
    "in the two-dimensional plane. Next, we create a linear boundary\n",
    "and assign the class probabilities according to proximity to the\n",
    "boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta = np.array([1,-1,1]) # last coordinate for affine offset\n",
    "prd = X.dot(beta)\n",
    "probs = 1/(1+np.exp(-prd/np.linalg.norm(beta)))\n",
    "c = (prd>0) # boolean array class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This establishes the training data.  The next block\n",
    "creates the logistic regression object and fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "_=lr.fit(X[:,:-1],c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have to omit the third dimension because of\n",
    "how Scikit-learn internally breaks down the components of the\n",
    "boundary. The resulting code extracts the corresponding\n",
    "$\\boldsymbol{\\beta}$ from the `LogisticRegression` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betah = np.r_[lr.coef_.flat,lr.intercept_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Programming Tip.**\n",
    "\n",
    "The Numpy `np.r_`  object provides a quick way to stack Numpy\n",
    "arrays horizontally instead of using `np.hstack`.\n",
    "\n",
    "\n",
    "\n",
    " The resulting boundary is shown in the left panel in\n",
    "[Figure](#fig:logreg_004). The crosses and triangles represent the two classes\n",
    "we\n",
    "created above, along with the separating gray line.  The logistic regression\n",
    "fit produces the dotted black line. The dark circle is the point that logistic\n",
    "regression categorizes incorrectly. The regularization parameter is $C=1$ by\n",
    "default. Next, we can change the strength of the regularization parameter as in\n",
    "the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the re-fit the data to produce the right panel in\n",
    "[Figure](#fig:logreg_004). By increasing the regularization\n",
    "parameter, we essentially nudged the fitting algorithm to\n",
    "*believe* the data more than the general model. That is, by doing\n",
    "this we accepted more variance in exchange for better bias.\n",
    "\n",
    "<!-- dom:FIGURE: [fig-machine_learning/logreg_004.png, width=500 frac=1.25]  The\n",
    "left panel shows the resulting boundary (dashed line) with $C=1$ as the\n",
    "regularization parameter. The right panel is for $C=1000$. The gray line is the\n",
    "boundary used to assign the class membership for the synthetic data. The dark\n",
    "circle is the point that logistic regression categorizes incorrectly. <div\n",
    "id=\"fig:logreg_004\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:logreg_004\"></div>\n",
    "\n",
    "<p>The left panel shows the resulting boundary (dashed line) with $C=1$ as the\n",
    "regularization parameter. The right panel is for $C=1000$. The gray line is the\n",
    "boundary used to assign the class membership for the synthetic data. The dark\n",
    "circle is the point that logistic regression categorizes incorrectly.</p>\n",
    "<img src=\"fig-machine_learning/logreg_004.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "## Generalized Linear Models\n",
    "\n",
    "Logistic regression is one example of a wider class of generalized linear\n",
    "models that embed non-linear transformations in the fitting process. Let's back\n",
    "up and break down logistic regression into smaller parts. As usual, we want to\n",
    "estimate the conditional expectation $\\mathbb{E}(Y\\vert X=\\mathbf{x})$.  For\n",
    "plain linear regression, we have the following approximation,\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(Y\\vert X=\\mathbf{x})\\approx\\boldsymbol{\\beta}^T\\mathbf{x}\n",
    "$$\n",
    "\n",
    " For notation sake, we call $r(x):=\\mathbb{E}(Y\\vert X=\\mathbf{x})$\n",
    "the response. For logistic regression, because $Y\\in\\left\\{0,1\\right\\}$, we\n",
    "have $\\mathbb{E}(Y\\vert X=\\mathbf{x})=\\mathbb{P}(Y\\vert X=\\mathbf{x})$ and the\n",
    "transformation makes $r(\\mathbf{x})$ linear.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\eta(\\mathbf{x}) &= \\boldsymbol{\\beta}^T\\mathbf{x}     \\\\\\\n",
    "        &= \\log \\frac{r(\\mathbf{x})}{1-r(\\mathbf{x})}  \\\\\\\n",
    "        &= g(r(\\mathbf{x}))\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    " where $g$ is defined as the logistic *link* function.\n",
    "The $\\eta(x)$ function is the linear predictor. Now that we have\n",
    "transformed the original data space using the logistic function to\n",
    "create the setting for the linear predictor, why don't we just do\n",
    "the same thing for the $Y_i$ data? That is, for plain linear\n",
    "regression, we usually take data, $\\left\\{X_i,Y_i\\right\\}$ and\n",
    "then use it to fit an approximation to $\\mathbb{E}(Y\\vert X=x)$.\n",
    "If we are transforming the conditional expectation using the\n",
    "logarithm, which we are approximating using $Y_i$, then why don't\n",
    "we correspondingly transform the binary $Y_i$ data? The answer is\n",
    "that if we did so then we would get the logarithm of zero (i.e.,\n",
    "infinity) or one (i.e., zero), which is not workable. The\n",
    "alternative is to use a linear Taylor approximation, like we did\n",
    "earlier with the delta method, to expand the $g$ function around\n",
    "$r(x)$, as in the following,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "g(Y) &\\approx \\log\\frac{r(x)}{1-r(x)} + \\frac{Y-r(x)}{r(x)-r(x)^2} \\\\\\\n",
    "     &= \\eta(x)+ \\frac{Y-r(x)}{r(x)-r(x)^2}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    " The interesting part is the $Y-r(x)$ term, because this is where the\n",
    "class label data enters the problem. The expectation $\\mathbb{E}(Y-r(x)\\vert\n",
    "X)=0$ so we can think of this differential as additive noise that dithers\n",
    "$\\eta(x)$. The variance of $g(Y)$ is the following,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{V}(g(Y)\\vert X)&= \\mathbb{V}(\\eta(x)\\vert X)+\\frac{1}{(r(x)(1-r(x)))^2}\n",
    "\\mathbb{V}(Y-r(x)\\vert X) \\\\\\\n",
    "                       &=\\frac{1}{(r(x)(1-r(x)))^2} \\mathbb{V}(Y-r(x)\\vert X)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    " Note that $\\mathbb{V}(Y\\vert X)=r(x)(1-r(x))$ because $Y$ is\n",
    "a binary variable. Ultimately, this boils down to the following,\n",
    "\n",
    "$$\n",
    "\\mathbb{V}(g(Y)\\vert X)=\\frac{1}{r(x)(1-r(x))}\n",
    "$$\n",
    "\n",
    " Note that the variance is a function of $x$, which means it is\n",
    "*heteroskedastic*, meaning that the iterative minimum-variance-finding\n",
    "algorithm that computes $\\boldsymbol{\\beta}$ downplays $x$ where $r(x)\\approx\n",
    "0$ and $r(x)\\approx 1$ because the peak of the variance occurs where\n",
    "$r(x)\\approx 0.5$, which are those equivocal points are close to the boundary.\n",
    "\n",
    "\n",
    "For generalized linear models, the above sequence is the same and consists of\n",
    "three primary ingredients: the linear predictor ($\\eta(x)$), the link function\n",
    "($g(x)$), and the *dispersion scale function*, $V_{ds}$ such that\n",
    "$\\mathbb{V}(Y\\vert X)=\\sigma^2 V_{ds}(r(x))$. For logistic regression, we have\n",
    "$V_{ds}(r(x))=r(x)(1-r(x))$ and $\\sigma^2=1$. Note that absolute knowledge of\n",
    "$\\sigma^2$ is not important because the iterative algorithm needs only a\n",
    "relative proportional scale. To sum up, the iterative algorithm takes a linear\n",
    "prediction for $\\eta(x_i)$, computes the transformed responses, $g(Y_i)$,\n",
    "calculates the weights $w_i=\\left[(g^\\prime(r(x_i))V_{ds}(r(x_i)))\n",
    "\\right]^{-1}$, and then does a weighted linear regression of $g(y_i)$ onto\n",
    "$x_i$ with the weights $w_i$ to compute the next $\\boldsymbol{\\beta}$.\n",
    "More details can be found in the following [[fox2015applied]](#fox2015applied),\n",
    "[[lindsey1997applying]](#lindsey1997applying),\n",
    "[[campbell2009generalized]](#campbell2009generalized).\n",
    "\n",
    "\n",
    "<!-- # *Applied Predictive Modeling by Kuhn*, p. 283, -->\n",
    "<!-- # Logit function, odds ratio -->\n",
    "<!-- # *generalized linear models by Rodriguez*, p.72 -->\n",
    "<!-- # *Scikit-learn cookbook*, p.78 -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
